# GSP329 Integrate with Machine Learning APIs: Challenge Lab

Quests URL: https://www.qwiklabs.com/quests/136 (Advanced)

Topics tested

1. Grant the service account admin privileges for BigQuery and Cloud Storage.
1. Create and download a service account credentials file to provide Google Cloud credentials to a Python application.
1. Modify a Python script to extract text from image files using the Google Cloud Vision API.
1. Modify a Python script to translate text using the Google Translate API.
1. Check which languages are in the extracted data by executing a BigQuery SQL query.


The processed text data must then be written out to a pre-existing BigQuery table called `image_text_detail` in a dataset in your project called `image_classification_dataset`.


All of them are preceded with a comment using the label `# TBD:`


The code to do this is in the script but you must remove the comment characters to enable the line of code at the end of the script.


Confirm that image data has been successfully processed by running the following Query in BigQuery:

SELECT locale,COUNT(locale) as lcount FROM image_classification_dataset.image_text_detail GROUP BY locale ORDER BY lcount DESC

## Task 1: Configure a service account to access the Machine Learning APIs, BigQuery, and Cloud Storage

Tip 1. You do not need to provide any specific permissions to a service account to access most of the Google Machine Learning APIs such as the Google Cloud Vision and Translation APIs. The Python script does need permissions to access BigQuery and to create objects in Cloud Storage. The easiest way to do that is to bind the service account to `roles/bigquery.admin` and `roles/storage.objectAdmin`.

```bash
export PROJECT=<your_project_name>

gcloud iam service-accounts create my-account --display-name my-account
gcloud projects add-iam-policy-binding $PROJECT --member=serviceAccount:my-account@$PROJECT.iam.gserviceaccount.com --role=roles/bigquery.admin
gcloud iam service-accounts keys create key.json --iam-account=my-account@$PROJECT.iam.gserviceaccount.com
export GOOGLE_APPLICATION_CREDENTIALS=key.json
```

## Task 2: Create and download a credential file for your Service Account

Tip 2. You must set an environment variable to provide the details of the credentials file that should be used by the Python script to access the Google Cloud APIs.

## Task 3: Modify the Python script to extract text from image files

python3 

{
  "requests": [
      {
        "image": {
          "source": {
              "gcsImageUri": "gs://my-bucket-name/sign.jpg"
          }
        },
        "features": [
          {
            "type": "TEXT_DETECTION",
            "maxResults": 10
          }
        ]
      }
  ]
}

curl -s -X POST -H "Content-Type: application/json" --data-binary @ocr-request.json  https://vision.googleapis.com/v1/images:annotate?key=${API_KEY}

## Task 4: Modify the Python script to translate the text using the Translation API

Tip 3. You can find details about the Vision API Client `document_text_detection` API call in the [Python API Documentation reference page for the Vision API Client](https://googleapis.dev/python/vision/latest/gapic/v1/api.html#google.cloud.vision_v1.ImageAnnotatorClientdocument_text_detection) and the details of the Vision API annotation response object in the [Python API Documentation reference page for the Vision API Objects](https://googleapis.dev/python/vision/latest/gapic/v1/types.html#google.cloud.vision_v1.types.AnnotateImageResponse)

translation-request.json

{
  "q": "your_text_here",
  "target": "en"
}

STR=$(jq .responses[0].textAnnotations[0].description ocr-response.json) && STR="${STR//\"}" && sed -i "s|your_text_here|$STR|g" translation-request.json

curl -s -X POST -H "Content-Type: application/json" --data-binary @translation-request.json https://translation.googleapis.com/language/translate/v2?key=${API_KEY} -o translation-response.json

cat translation-response.json

## Task 5: Identify the most common non-English language used in the signs in the data set

Tip 4. For details about the Translation API Client translate API call, see the [Python API Documentation for the Translation V2 API Client](https://googleapis.dev/python/translation/2.0.1/client.html#google.cloud.translate_v2.client.Client.translate)

nl-request.json

{
  "document":{
    "type":"PLAIN_TEXT",
    "content":"your_text_here"
  },
  "encodingType":"UTF8"
}

STR=$(jq .data.translations[0].translatedText  translation-response.json) && STR="${STR//\"}" && sed -i "s|your_text_here|$STR|g" nl-request.json

curl "https://language.googleapis.com/v1/documents:analyzeEntities?key=${API_KEY}" \
  -s -X POST -H "Content-Type: application/json" --data-binary @nl-request.json



Hints: [Extract, Analyze, and Translate Text from Images with the Cloud ML APIs](https://www.qwiklabs.com/focuses/1836?parent=catalog)

[Classify Text into Categories with the Natural Language API](https://www.qwiklabs.com/focuses/1749?parent=catalog)

Hints: https://codelabs.developers.google.com/codelabs/cloud-ml-apis/index.html

Hints: https://medium.com/@ajiltu5467/integrate-with-machine-learning-apis-challenge-lab-tutorial-4ed8c5cb983e


Create a new service account that provides credentials for the script.
export SANAME=challenge
gcloud iam service-accounts create $SANAME
Once you have created the account, bind the BigQuery Admin and Cloud Storage Admin roles to the Service Account to provide the IAM permissions required to process files from Cloud Storage and insert the result data into a BigQuery table.
1) gcloud projects add-iam-policy-binding $DEVSHELL_PROJECT_ID --member=serviceAccount:$SANAME@$DEVSHELL_PROJECT_ID.iam.gserviceaccount.com --role=roles/bigquery.admin
2) gcloud projects add-iam-policy-binding $DEVSHELL_PROJECT_ID --member=serviceAccount:$SANAME@$DEVSHELL_PROJECT_ID.iam.gserviceaccount.com --role=roles/storage.admin